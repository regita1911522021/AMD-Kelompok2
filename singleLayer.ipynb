{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "singleLayer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WGH5YKOLFG3w"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv('bunga.csv')\n",
        "data.columns=['Sepal_len_cm','Sepal_wid_cm','Petal_len_cm','Petal_wid_cm','Type']\n",
        "data.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "u1xmwwtoFkvo",
        "outputId": "11731617-1eac-48c7-e6bb-c9fea08d5bfe"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Sepal_len_cm  Sepal_wid_cm  Petal_len_cm  Petal_wid_cm  Type\n",
              "0           4.9           3.0           1.4           0.2     0\n",
              "1           4.7           3.2           1.3           0.2     0\n",
              "2           4.6           3.1           1.5           0.2     0\n",
              "3           5.0           3.6           1.4           0.2     0\n",
              "4           5.4           3.9           1.7           0.4     0\n",
              "5           4.6           3.4           1.4           0.3     0\n",
              "6           5.0           3.4           1.5           0.2     0\n",
              "7           4.4           2.9           1.4           0.2     0\n",
              "8           4.9           3.1           1.5           0.1     0\n",
              "9           5.4           3.7           1.5           0.2     0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-20aa32fa-8ba1-400c-9834-53301b1d5674\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sepal_len_cm</th>\n",
              "      <th>Sepal_wid_cm</th>\n",
              "      <th>Petal_len_cm</th>\n",
              "      <th>Petal_wid_cm</th>\n",
              "      <th>Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.4</td>\n",
              "      <td>3.9</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>4.4</td>\n",
              "      <td>2.9</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>5.4</td>\n",
              "      <td>3.7</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-20aa32fa-8ba1-400c-9834-53301b1d5674')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-20aa32fa-8ba1-400c-9834-53301b1d5674 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-20aa32fa-8ba1-400c-9834-53301b1d5674');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def activation_func(value):    #Tangent Hypotenuse\n",
        "    #return (1/(1+np.exp(-value)))\n",
        "    return ((np.exp(value)-np.exp(-value))/(np.exp(value)+np.exp(-value)))"
      ],
      "metadata": {
        "id": "PyLQreJIFqP6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perceptron_train(in_data,labels,alpha):\n",
        "    X=np.array(in_data)\n",
        "    y=np.array(labels)\n",
        "    weights=np.random.random(X.shape[1])\n",
        "    original=weights\n",
        "    bias=np.random.random_sample()\n",
        "    for key in range(X.shape[0]):\n",
        "        a=activation_func(np.matmul(np.transpose(weights),X[key]))     \n",
        "        yn=0\n",
        "        if a>=0.7:\n",
        "            yn=1\n",
        "        elif a<=(-0.7):\n",
        "            yn=-1\n",
        "        weights=weights+alpha*(yn-y[key])*X[key]\n",
        "        print('Iteration '+str(key)+': '+str(weights))\n",
        "    print('Difference: '+str(weights-original))\n",
        "    return weights"
      ],
      "metadata": {
        "id": "pa_SWw8WFv0s"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perceptron_test(in_data,label_shape,weights):\n",
        "    X=np.array(in_data)\n",
        "    y=np.zeros(label_shape)\n",
        "    for key in range(X.shape[1]):\n",
        "        a=activation_func((weights*X[key]).sum())\n",
        "        y[key]=0\n",
        "        if a>=0.7:\n",
        "            y[key]=1\n",
        "        elif a<=(-0.7):\n",
        "            y[key]=-1\n",
        "    return y"
      ],
      "metadata": {
        "id": "WdEdDdbkFyKh"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score(result,labels):\n",
        "    difference=result-np.array(labels)                                                        \n",
        "    correct_ctr=0\n",
        "    for elem in range(difference.shape[0]):\n",
        "        if difference[elem]==0:\n",
        "            correct_ctr+=1\n",
        "    score=correct_ctr*100/difference.size\n",
        "    print('Score='+str(score))"
      ],
      "metadata": {
        "id": "yspc3XugF0lG"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividing DataFrame \"data\" into \"d_train\" (60%) and \"d_test\" (40%)\n",
        "divider = np.random.rand(len(data)) < 0.70\n",
        "d_train=data[divider]\n",
        "d_test=data[~divider]"
      ],
      "metadata": {
        "id": "usYYwI1wF2zY"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividing d_train into data and labels/targets\n",
        "d_train_y=d_train['Type']\n",
        "d_train_X=d_train.drop(['Type'],axis=1)\n",
        "\n",
        "# Dividing d_train into data and labels/targets\n",
        "d_test_y=d_test['Type']\n",
        "d_test_X=d_test.drop(['Type'],axis=1)"
      ],
      "metadata": {
        "id": "PP_uyEbRF411"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Learning rate\n",
        "alpha = 0.01\n",
        "\n",
        "# Train\n",
        "weights = perceptron_train(d_train_X, d_train_y, alpha)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGRabJPwF7BU",
        "outputId": "665a6d37-33cf-42e7-8db1-9eedd2d1194a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0: [0.52502605 0.37491848 0.24606294 0.71830414]\n",
            "Iteration 1: [0.57502605 0.41091848 0.26006294 0.72030414]\n",
            "Iteration 2: [0.62902605 0.44991848 0.27706294 0.72430414]\n",
            "Iteration 3: [0.67902605 0.48391848 0.29206294 0.72630414]\n",
            "Iteration 4: [0.72302605 0.51291848 0.30606294 0.72830414]\n",
            "Iteration 5: [0.77202605 0.54391848 0.32106294 0.72930414]\n",
            "Iteration 6: [0.82602605 0.58091848 0.33606294 0.73130414]\n",
            "Iteration 7: [0.87402605 0.61091848 0.35006294 0.73230414]\n",
            "Iteration 8: [0.93102605 0.65491848 0.36506294 0.73630414]\n",
            "Iteration 9: [0.98502605 0.68891848 0.38206294 0.73830414]\n",
            "Iteration 10: [1.03102605 0.72491848 0.39206294 0.74030414]\n",
            "Iteration 11: [1.08202605 0.75791848 0.40906294 0.74530414]\n",
            "Iteration 12: [1.13002605 0.79191848 0.42806294 0.74730414]\n",
            "Iteration 13: [1.18002605 0.82591848 0.44406294 0.75130414]\n",
            "Iteration 14: [1.23202605 0.86091848 0.45906294 0.75330414]\n",
            "Iteration 15: [1.28402605 0.89491848 0.47306294 0.75530414]\n",
            "Iteration 16: [1.33902605 0.92991848 0.48606294 0.75730414]\n",
            "Iteration 17: [1.38802605 0.96091848 0.50106294 0.75830414]\n",
            "Iteration 18: [1.43802605 0.99591848 0.51406294 0.76130414]\n",
            "Iteration 19: [1.48302605 1.01891848 0.52706294 0.76430414]\n",
            "Iteration 20: [1.52702605 1.05091848 0.54006294 0.76630414]\n",
            "Iteration 21: [1.57702605 1.08591848 0.55606294 0.77230414]\n",
            "Iteration 22: [1.62802605 1.12391848 0.57506294 0.77630414]\n",
            "Iteration 23: [1.75602605 1.18791848 0.66506294 0.80630414]\n",
            "Iteration 24: [1.89402605 1.24991848 0.76306294 0.83630414]\n",
            "Iteration 25: [2.00802605 1.30591848 0.85306294 0.86230414]\n",
            "Iteration 26: [2.10602605 1.35391848 0.91906294 0.88230414]\n",
            "Iteration 27: [2.21002605 1.40791848 0.99706294 0.91030414]\n",
            "Iteration 28: [2.33002605 1.45191848 1.07706294 0.93030414]\n",
            "Iteration 29: [2.45202605 1.50991848 1.17106294 0.95830414]\n",
            "Iteration 30: [2.56402605 1.56791848 1.24306294 0.98430414]\n",
            "Iteration 31: [2.69802605 1.62991848 1.33106294 1.01230414]\n",
            "Iteration 32: [2.81002605 1.68991848 1.42106294 1.04230414]\n",
            "Iteration 33: [2.92602605 1.74391848 1.50306294 1.06230414]\n",
            "Iteration 34: [3.05002605 1.78791848 1.59306294 1.09230414]\n",
            "Iteration 35: [3.16802605 1.85191848 1.68906294 1.12830414]\n",
            "Iteration 36: [3.29002605 1.90791848 1.76906294 1.15430414]\n",
            "Iteration 37: [3.41602605 1.95791848 1.86706294 1.18430414]\n",
            "Iteration 38: [3.54402605 2.01591848 1.95306294 1.21030414]\n",
            "Iteration 39: [3.67602605 2.07591848 2.04106294 1.23830414]\n",
            "Iteration 40: [3.81202605 2.13191848 2.13706294 1.26630414]\n",
            "Iteration 41: [3.94602605 2.19191848 2.23706294 1.30030414]\n",
            "Iteration 42: [4.06002605 2.24391848 2.30706294 1.32030414]\n",
            "Iteration 43: [4.17002605 2.29191848 2.38106294 1.34030414]\n",
            "Iteration 44: [4.28602605 2.34591848 2.45906294 1.36430414]\n",
            "Iteration 45: [4.40602605 2.39991848 2.56106294 1.39630414]\n",
            "Iteration 46: [4.51402605 2.45991848 2.65106294 1.42630414]\n",
            "Iteration 47: [4.63402605 2.52791848 2.74106294 1.45830414]\n",
            "Iteration 48: [4.76002605 2.57391848 2.82906294 1.48430414]\n",
            "Iteration 49: [4.87002605 2.62391848 2.90906294 1.51030414]\n",
            "Iteration 50: [4.98602605 2.67591848 2.98906294 1.53430414]\n",
            "Iteration 51: [5.10002605 2.73391848 3.07306294 1.56030414]\n",
            "Iteration 52: [5.22402605 2.79191848 3.15906294 1.58630414]\n",
            "Iteration 53: [5.32602605 2.84191848 3.21906294 1.60830414]\n",
            "Iteration 54: [5.32602605 2.84191848 3.21906294 1.60830414]\n",
            "Iteration 55: [5.32602605 2.84191848 3.21906294 1.60830414]\n",
            "Iteration 56: [5.32602605 2.84191848 3.21906294 1.60830414]\n",
            "Iteration 57: [5.32602605 2.84191848 3.21906294 1.60830414]\n",
            "Iteration 58: [5.32602605 2.84191848 3.21906294 1.60830414]\n",
            "Iteration 59: [5.32602605 2.84191848 3.21906294 1.60830414]\n",
            "Iteration 60: [5.32602605 2.84191848 3.21906294 1.60830414]\n",
            "Iteration 61: [5.32602605 2.84191848 3.21906294 1.60830414]\n",
            "Iteration 62: [5.32602605 2.84191848 3.21906294 1.60830414]\n",
            "Iteration 63: [5.32602605 2.84191848 3.21906294 1.60830414]\n",
            "Iteration 64: [5.32602605 2.84191848 3.21906294 1.60830414]\n",
            "Iteration 65: [5.32602605 2.84191848 3.21906294 1.60830414]\n",
            "Iteration 66: [5.32602605 2.84191848 3.21906294 1.60830414]\n",
            "Iteration 67: [5.32602605 2.84191848 3.21906294 1.60830414]\n",
            "Iteration 68: [5.32602605 2.84191848 3.21906294 1.60830414]\n",
            "Iteration 69: [5.32602605 2.84191848 3.21906294 1.60830414]\n",
            "Iteration 70: [5.32602605 2.84191848 3.21906294 1.60830414]\n",
            "Iteration 71: [5.32602605 2.84191848 3.21906294 1.60830414]\n",
            "Iteration 72: [5.32602605 2.84191848 3.21906294 1.60830414]\n",
            "Iteration 73: [5.32602605 2.84191848 3.21906294 1.60830414]\n",
            "Iteration 74: [5.32602605 2.84191848 3.21906294 1.60830414]\n",
            "Iteration 75: [5.32602605 2.84191848 3.21906294 1.60830414]\n",
            "Iteration 76: [5.32602605 2.84191848 3.21906294 1.60830414]\n",
            "Iteration 77: [5.32602605 2.84191848 3.21906294 1.60830414]\n",
            "Iteration 78: [5.32602605 2.84191848 3.21906294 1.60830414]\n",
            "Iteration 79: [5.32602605 2.84191848 3.21906294 1.60830414]\n",
            "Iteration 80: [5.32602605 2.84191848 3.21906294 1.60830414]\n",
            "Iteration 81: [5.32602605 2.84191848 3.21906294 1.60830414]\n",
            "Iteration 82: [5.32602605 2.84191848 3.21906294 1.60830414]\n",
            "Iteration 83: [5.32602605 2.84191848 3.21906294 1.60830414]\n",
            "Iteration 84: [5.32602605 2.84191848 3.21906294 1.60830414]\n",
            "Iteration 85: [5.32602605 2.84191848 3.21906294 1.60830414]\n",
            "Iteration 86: [5.32602605 2.84191848 3.21906294 1.60830414]\n",
            "Iteration 87: [5.32602605 2.84191848 3.21906294 1.60830414]\n",
            "Iteration 88: [5.32602605 2.84191848 3.21906294 1.60830414]\n",
            "Iteration 89: [5.32602605 2.84191848 3.21906294 1.60830414]\n",
            "Iteration 90: [5.32602605 2.84191848 3.21906294 1.60830414]\n",
            "Iteration 91: [5.32602605 2.84191848 3.21906294 1.60830414]\n",
            "Difference: [4.847 2.498 2.988 0.892]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "result_test=perceptron_test(d_test_X,d_test_y.shape,weights)"
      ],
      "metadata": {
        "id": "jfekHU6cF-IY"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate score\n",
        "score(result_test,d_test_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-k-HlRi8GAM5",
        "outputId": "5c1d7bff-b480-4713-9a06-c22a052648fb"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score=38.59649122807018\n"
          ]
        }
      ]
    }
  ]
}